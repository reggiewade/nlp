{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19693eab-fef8-43e1-a3a4-c687b080cd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "# check if the GPU is detected\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a586c73-f802-4e11-868a-0ab6831eb715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/reggie/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download TinyLlama 1.1B\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(repo_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", filename=\"config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2795bf3-2182-4224-9585-3edde6744f29",
   "metadata": {},
   "source": [
    "### Load and Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f8d094-e21f-4c5c-9b61-a4718925179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675, 76)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "raw_data = pd.read_csv('swim_dataset.csv')\n",
    "raw_data\n",
    "\n",
    "# split to train and eval\n",
    "train_data, eval_data = train_test_split(raw_data, test_size=0.1, random_state=42)\n",
    "len(train_data), len(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78293eb-afb1-4860-8f79-042a26d0c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data format\n",
    "def preprocess(example):\n",
    "    return {\n",
    "        \"text\": f\"<|system|> You are Swim Instructor helping athletes <|user|> {example['Question']} <|assistant|> {example['Answer']}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897d2f43-fcd9-4000-a1ee-4f9ead06ea17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e688b2318078497891bf9406a97f3dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/675 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94684278f72645bbbcdd2d6c3f121551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "# load dataset/preprocess\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "eval_dataset = Dataset.from_pandas(eval_data)\n",
    "train_data = train_dataset.map(preprocess)\n",
    "eval_data = eval_dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509cf10c-2e09-47b2-9f98-0dea427f4b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|system|> You are Swim Instructor helping athletes <|user|> What is the best time to do dryland training in relation to swim practice? <|assistant|> It's often best to do dryland workouts after swimming or on separate days to avoid fatigue affecting swim performance.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3056522-afe3-458d-90e7-8b53b34e173f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreggienwade\u001b[0m (\u001b[33mreggienwade-boise-state-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/reggie/dev/CS436/nlp/neo_fine_tuning/wandb/run-20250501_225947-vwvmqej0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/reggienwade-boise-state-university/swim_coach_llama/runs/vwvmqej0' target=\"_blank\">run2-10epochs</a></strong> to <a href='https://wandb.ai/reggienwade-boise-state-university/swim_coach_llama' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/reggienwade-boise-state-university/swim_coach_llama' target=\"_blank\">https://wandb.ai/reggienwade-boise-state-university/swim_coach_llama</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/reggienwade-boise-state-university/swim_coach_llama/runs/vwvmqej0' target=\"_blank\">https://wandb.ai/reggienwade-boise-state-university/swim_coach_llama/runs/vwvmqej0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/reggienwade-boise-state-university/swim_coach_llama/runs/vwvmqej0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb83e55fbb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"swim_coach_llama\",\n",
    "    name=\"run2-10epochs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862677c-f987-4e08-a14b-759de05a0937",
   "metadata": {},
   "source": [
    "### Define Model and Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7756f5-9a1e-4f4b-a58c-c8493916fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8d32635-8280-4075-bfc0-8508902bb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoProcessor, AutoModelForCausalLM, BitsAndBytesConfig, EarlyStoppingCallback\n",
    "\n",
    "def get_model_and_tokenizer(model_id):\n",
    "    tokenizer = AutoProcessor.from_pretrained(model_id)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # store the weights (parameters) of the model in 4-bit to save v-ram\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=\"float16\",\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )  \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")    \n",
    "    model.config.use_cache = False\n",
    "    # keep tensors on one device\n",
    "    model.config.pretraining_tp = 1\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = get_model_and_tokenizer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7523b56-9a08-45c0-a62e-70e95d2b3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, prompt, max_length=300, temperature=0.7, top_p=0.9, do_sample=True):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        do_sample=do_sample,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6ba1a-2fcf-4638-8a01-f861b2e7820f",
   "metadata": {},
   "source": [
    "### Evaluate Baseline using BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36cddeca-4a70-4ea4-b630-151a9aaf6726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "def calculateBLEU(eval_set, model):\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    \n",
    "    for row in tqdm(eval_data):\n",
    "        curr_query = ('<|system|> You are Swim Instructor helping athletes <|user|> ' + row['Question'])\n",
    "        reference = row['text'].split()\n",
    "        hypothesis = generate(model, curr_query).split()\n",
    "\n",
    "        # skip over if LLM failed to generate\n",
    "        if len(hypothesis) < 9:\n",
    "            continue\n",
    "    \n",
    "        references.append(reference)\n",
    "        hypotheses.append(hypothesis)\n",
    "    \n",
    "    corpus_bleu_score = corpus_bleu(references, hypotheses, smoothing_function=SmoothingFunction().method1)\n",
    "    return corpus_bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0fb43e9-57c6-4cd8-a64d-c8326634e2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bd7810baf749e2926211ddc05803d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU Score: 0.0001\n"
     ]
    }
   ],
   "source": [
    "print(f\"Corpus BLEU Score: {calculateBLEU(eval_data, model):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a958c923-56ef-4ee7-9e4a-102cbb9cf76c",
   "metadata": {},
   "source": [
    "### Evaluate Baseline using ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec07f73b-d30f-41c5-8594-c47d8df7001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def calculateROUGE(eval_set, model):\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "\n",
    "    for row in tqdm(eval_data):\n",
    "        curr_query = ('<|system|> You are Swim Instructor helping athletes <|user|> ' + row['Question'])\n",
    "        reference = row['text']\n",
    "        hypothesis = generate(model, curr_query)\n",
    "\n",
    "        # skip over if LLM failed to generate\n",
    "        if len(hypothesis) < 9:\n",
    "            continue\n",
    "\n",
    "        references.append(reference)\n",
    "        hypotheses.append(hypothesis)\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(hypotheses, references, avg=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "136f1609-76e4-4de4-ab41-56ab91249589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c62a6b1e9564851a9d54064e66f1ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus ROUGE Score: {'rouge-1': {'r': 0.5666637803067068, 'p': 0.6384504535271867, 'f': 0.5271197903493715}, 'rouge-2': {'r': 0.4862746078980227, 'p': 0.5805493675324449, 'f': 0.4401218056640395}, 'rouge-l': {'r': 0.5647033568292554, 'p': 0.6376540773603455, 'f': 0.5259933085835715}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Corpus ROUGE Score: {calculateROUGE(eval_data, model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c35d0a-2fce-4322-8685-f6b575525450",
   "metadata": {},
   "source": [
    "### Test QA on Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4216abb-3a69-455a-b384-e8e5dd505ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|> You are Swim Instructor helping athletes <|user|> How can I improve my distance per stroke? Answer according to: Can you suggest some exercises to improve my distance per stroke? Answer according to: The longer you swim, the more you’ll improve your distance per stroke. The more distance you cover, the more you’ll build strength and endurance. But even if you’re not a swimmer, you can still improve your distance by doing the exercises below. First, you’ll want to make sure you’re in a good state of form before you start doing these exercises. If you’re not sure, take a break from swimming and do some plyometric exercises to get your heart rate up.\n",
      "First, you’ll want to make sure you’re in a good state of form before you start doing these exercises. If you’re not\n"
     ]
    }
   ],
   "source": [
    "response = generate(model, \"<|system|> You are Swim Instructor helping athletes <|user|> How can I improve my distance per stroke?\", max_length=200)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6c1832-e8bf-4f03-8617-eff6c671fa02",
   "metadata": {},
   "source": [
    "### Define LoRs Config and Training Regimine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e92a7eca-bab8-445e-a886-84684eb76a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "# LoRa config\n",
    "peft_config = LoraConfig(\n",
    "    r=64,    # size of low rank matricies\n",
    "    lora_alpha=32,    # scaling factor\n",
    "    lora_dropout=0.08,  # Regularization via dropout\n",
    "    bias='none',    # don't edit the bias of original model\n",
    "    task_type=\"CAUSAL_LM\",    # tells Lora this is a generation model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "152f13cd-ba76-4b7f-9878-3f659d63ce38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705ae3dcd5c74a5bb5cad708497121af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/675 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350ffdb1e22048318592808876573e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/675 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22471b28785043029a5e55256d5a83a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/675 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ac9f298dbd40efbf04d0ff3fcdde47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/675 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb625449bb9c45008899141cde234ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c353be1dea46d3a7a0e3bdb9fc2885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9dfab331a2c4cfca5546f127aa0120e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3185287c57e341cbaae3811fd6c4a3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"swim_coach_llama_64\",\n",
    "    dataset_text_field=\"text\",\n",
    "    packing=False,  # Set to True if you want data packing\n",
    "    max_seq_length=1024,    # max token length accepted, anything longer will be truncated\n",
    "    per_device_train_batch_size=16,    # batch size (essentially 64 because of next line)\n",
    "    gradient_accumulation_steps=4,    # accumulate gradients across 4 batches before back-prop\n",
    "    optim=\"paged_adamw_32bit\",    # define optimization function\n",
    "    learning_rate=2e-4,    # learning rate\n",
    "    lr_scheduler_type=\"cosine\",    # learning rate scheduler\n",
    "    save_strategy=\"epoch\",   # defines where to save checkpoints\n",
    "    save_steps=10,    # how often to save checkpoint\n",
    "    logging_steps=1,     # how often to log info\n",
    "    num_train_epochs=10,    # number of epochs\n",
    "    max_steps=200,    # max number of training steps\n",
    "    fp16=True,    # train on mixed precision (16bit floats)\n",
    "    eval_strategy=\"steps\",  # Evaluate regularly\n",
    "    eval_steps=10,    # how often to evaluate\n",
    "    save_total_limit=10,           # Keep only last N checkpoints\n",
    "    metric_for_best_model=\"eval_loss\",  # Use eval_loss to find the best model\n",
    "    greater_is_better=False,      # Lower eval_loss is better\n",
    ")\n",
    "# Trainer with validation dataset\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    "    args=sft_config,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=10)],  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaeb8512-a0bc-4638-a2c6-ffd2f7d58077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 12:59, Epoch 18/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.921500</td>\n",
       "      <td>1.814044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.368200</td>\n",
       "      <td>1.352496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.156400</td>\n",
       "      <td>1.233001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.229600</td>\n",
       "      <td>1.188865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.175300</td>\n",
       "      <td>1.156014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.138800</td>\n",
       "      <td>1.131532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.083800</td>\n",
       "      <td>1.114419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.064900</td>\n",
       "      <td>1.098348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.040600</td>\n",
       "      <td>1.086983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.054300</td>\n",
       "      <td>1.078204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.001500</td>\n",
       "      <td>1.071825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.007000</td>\n",
       "      <td>1.065149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.976100</td>\n",
       "      <td>1.062247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.974100</td>\n",
       "      <td>1.058236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>1.057047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.937900</td>\n",
       "      <td>1.054998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.912700</td>\n",
       "      <td>1.053756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.943700</td>\n",
       "      <td>1.053577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.965500</td>\n",
       "      <td>1.053685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.909600</td>\n",
       "      <td>1.053625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=1.1353641149401665, metrics={'train_runtime': 781.6939, 'train_samples_per_second': 16.375, 'train_steps_per_second': 0.256, 'total_flos': 6124924109438976.0, 'train_loss': 1.1353641149401665})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9085d6-666b-4edf-bbbb-4462cd18fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    load_in_8bit=False, \n",
    "    device_map=\"auto\", \n",
    "    trust_remote_code=True,\n",
    "    use_flash_attention_2=False,\n",
    ")\n",
    "\n",
    "#modify the folder according to which checkpoint has the best eval_score! (lower is better)\n",
    "model_path = \"./swim_coach_llama_64/checkpoint-198\"\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model, model_path, from_transformers=True, device_map=\"auto\")\n",
    "model = peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51339343-8284-4d8e-98e7-82d246f8f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|> You are Swim Instructor helping athletes <|user|> How can I develop an early vertical forearm? <|assistant|> Start with a light kick, catch your breath, and gradually work your way up.\n"
     ]
    }
   ],
   "source": [
    "response = generate(model, \"<|system|> You are Swim Instructor helping athletes <|user|> How can I develop an early vertical forearm?\", max_length=350)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe13388-cbb2-40bd-a2e8-6364c55a4367",
   "metadata": {},
   "source": [
    "### Calculate BLEU Score post fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ceed85a-7b31-45d2-9042-3a714ea05dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07057b9bf0e046d6a63fa199eb8d4f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU Score: 0.0002\n"
     ]
    }
   ],
   "source": [
    "print(f\"Corpus BLEU Score: {calculateBLEU(eval_data, model):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f338afc-651a-404d-af93-e4a1249c251c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24314bd38a04febb9043f0d225a7f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus ROUGE Score: {'rouge-1': {'r': 0.6414817724953342, 'p': 0.6464909690526827, 'f': 0.6419120388185374}, 'rouge-2': {'r': 0.5414242616589967, 'p': 0.536292097271519, 'f': 0.5364554575505489}, 'rouge-l': {'r': 0.6285719485328878, 'p': 0.6338201443484348, 'f': 0.6291532247547832}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Corpus ROUGE Score: {calculateROUGE(eval_data, model)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
