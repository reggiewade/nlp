{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18635308-4bc7-4391-811c-afb7c9b67609",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a426d55-8b9d-4e96-95d9-0c900f2fb13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    This class loads and preprocesses the given text data\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, tokenizer):\n",
    "        \"\"\"\n",
    "        This function initialises the object. It takes the given paths and tokeniser.\n",
    "        \"\"\"\n",
    "        self.paths = paths\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = self.read_file(self.paths[0])\n",
    "        self.current_file = 0\n",
    "        self.offset = 0\n",
    "        self.remaining = len(self.data)\n",
    "        \n",
    "         # get length\n",
    "        self.length = 0\n",
    "        for path in self.paths: \n",
    "            print(len(self.read_file(path)))\n",
    "            self.length += len(self.read_file(path))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        returns the length of the ds\n",
    "        \"\"\"\n",
    "        return self.length\n",
    "        #return 1058750 # pre-calculated length of 10M data set\n",
    "        #return 10587561\n",
    "    \n",
    "    def read_file(self, path):\n",
    "        \"\"\"\n",
    "        reads a given file\n",
    "        \"\"\"\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "        return lines\n",
    "\n",
    "    def get_encodings(self, lines_all):\n",
    "        \"\"\"\n",
    "        Creates encodings for a given text input\n",
    "        \"\"\"\n",
    "        # tokenise all text \n",
    "        batch = self.tokenizer(lines_all, max_length=128, padding='max_length', truncation=True)\n",
    "\n",
    "        # Ground Truth\n",
    "        labels = torch.tensor(batch['input_ids'])\n",
    "        # Attention Masks\n",
    "        mask = torch.tensor(batch['attention_mask'])\n",
    "\n",
    "        # Input to be masked\n",
    "        input_ids = labels.detach().clone()\n",
    "        rand = torch.rand(input_ids.shape)\n",
    "\n",
    "        # with a probability of 15%, mask a given word, leave out CLS, SEP and PAD\n",
    "        mask_arr = (rand < .15) * (input_ids != 0) * (input_ids != 2) * (input_ids != 3)\n",
    "        # assign token 4 (=MASK)\n",
    "        input_ids[mask_arr] = 4\n",
    "        \n",
    "        return {'input_ids':input_ids, 'attention_mask':mask, 'labels':labels}\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        returns item i\n",
    "        Note: do not use shuffling for this dataset\n",
    "        \"\"\"\n",
    "        # if we have looked at all items in the file - take next\n",
    "        if self.remaining == 0:\n",
    "            self.offset += len(self.data)\n",
    "            self.current_file += 1\n",
    "            # if we are at the end of the dataset, start over again\n",
    "            if self.current_file == len(self.paths):\n",
    "                self.current_file = 0\n",
    "            # self.get_encodings(self.data)\n",
    "            print(\"reading {}\".format(self.paths[self.current_file]))\n",
    "            self.data = self.read_file(self.paths[self.current_file])\n",
    "            self.remaining = len(self.data)\n",
    "        \n",
    "        # reset offset when i is reset\n",
    "        if i == 0:\n",
    "            self.offset = 0\n",
    "        \n",
    "        self.remaining -= 1\n",
    "\n",
    "        encodings = self.get_encodings(self.data[i - self.offset])\n",
    "\n",
    "        return encodings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb5a80-d14b-4633-b7fe-dee478057306",
   "metadata": {},
   "source": [
    "### Set up electra tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a8d5b3-56f1-4ba5-b55f-81499f0849da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 7592, 1010, 2129, 2024, 2017, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] hello, how are you? [SEP]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import ElectraTokenizerFast\n",
    "from transformers import ElectraConfig\n",
    "from transformers import ElectraForMaskedLM\n",
    "\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained('google/electra-small-discriminator')\n",
    "\n",
    "tokens = tokenizer('Hello, how are you?')\n",
    "print(tokens)\n",
    "# {'input_ids': [2, 21694, 16, 2287, 2009, 1991, 35, 3],\n",
    "# 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
    "\n",
    "tokenizer.decode(tokens['input_ids'])\n",
    "# '[CLS] hello, how are you? [SEP]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f6a9df-5d1a-4ec4-b2bc-b3b8ef393b42",
   "metadata": {},
   "source": [
    "### Grab all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f033145-e141-40cd-84f1-3b8818c39dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90001\n",
      "580001\n",
      "66015\n",
      "360001\n",
      "65001\n",
      "18001\n"
     ]
    }
   ],
   "source": [
    "# load dataset files one by one\n",
    "paths = [str(x) for x in Path('train_10M').glob('**/*.train')]\n",
    "ds = Dataset(paths, tokenizer=tokenizer)\n",
    "# tokenize data with batch size 16\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4466bd-9f0b-4ea4-a6b6-e8759548948a",
   "metadata": {},
   "source": [
    "### Get Electra Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ee29c5-6528-4695-84cf-3c1d02b51946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForMaskedLM(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 64, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 64)\n",
       "      (token_type_embeddings): Embedding(2, 64)\n",
       "      (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=64, out_features=196, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-17): 18 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=196, out_features=196, bias=True)\n",
       "              (key): Linear(in_features=196, out_features=196, bias=True)\n",
       "              (value): Linear(in_features=196, out_features=196, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=196, out_features=196, bias=True)\n",
       "              (LayerNorm): LayerNorm((196,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=196, out_features=128, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=128, out_features=196, bias=True)\n",
       "            (LayerNorm): LayerNorm((196,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator_predictions): ElectraGeneratorPredictions(\n",
       "    (activation): GELUActivation()\n",
       "    (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=196, out_features=64, bias=True)\n",
       "  )\n",
       "  (generator_lm_head): Linear(in_features=64, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL to the config file\n",
    "config_url = \"https://huggingface.co/bsu-slim/electra-tiny/resolve/main/config.json\"\n",
    "\n",
    "# Download the config file\n",
    "response = requests.get(config_url)\n",
    "\n",
    "# Load the JSON content into ElectraConfig using .from_dict\n",
    "config = ElectraConfig.from_dict(response.json())\n",
    "model = ElectraForMaskedLM(config)\n",
    "optim=torch.optim.Adam(model.parameters())\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d9d1f8-12d7-4223-bd61-2185f643f6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"electra_owt_full_b256_hs196_ah4_is128_l18_es64_vs30522_pytorch\",\n",
       "  \"architectures\": [\n",
       "    \"ElectraForPreTraining\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"embedding_size\": 64,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 196,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 128,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"electra\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 18,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"summary_activation\": \"gelu\",\n",
       "  \"summary_last_dropout\": 0.1,\n",
       "  \"summary_type\": \"first\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.49.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1fba014-9336-472e-a1e7-9e65d17ecd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5be050b988b4179b7bcc501765e6c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     33\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Training Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean(losses))\n\u001b[0;32m     36\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     37\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(test_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    # iterate over dataset\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # copy input to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # predict\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        # update weights\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        # output current loss\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    print(\"Mean Training Loss\", np.mean(losses))\n",
    "    losses = []\n",
    "    loop = tqdm(test_loader, leave=True)\n",
    "\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # iterate over dataset\n",
    "    for batch in loop:\n",
    "        # copy input to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # predict\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        # update weights\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # output current loss\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        losses.append(loss.item())\n",
    "    print(\"Mean Test Loss\", np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4d3b0-f27c-4b41-8ecb-54108573e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pretrained model\n",
    "torch.save(model, \"electra_tiny.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cc89f-5fbc-4459-948c-30a8070b3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"electra_tiny.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
