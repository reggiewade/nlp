{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18635308-4bc7-4391-811c-afb7c9b67609",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a426d55-8b9d-4e96-95d9-0c900f2fb13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    This class loads and preprocesses the given text data\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, tokenizer):\n",
    "        \"\"\"\n",
    "        This function initialises the object. It takes the given paths and tokeniser.\n",
    "        \"\"\"\n",
    "        self.paths = paths\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = self.read_file(self.paths[0])\n",
    "        self.current_file = 0\n",
    "        self.offset = 0\n",
    "        self.remaining = len(self.data)\n",
    "        \n",
    "         # get length\n",
    "        self.length = 0\n",
    "        for path in self.paths: \n",
    "            print(len(self.read_file(path)))\n",
    "            self.length += len(self.read_file(path))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        returns the length of the ds\n",
    "        \"\"\"\n",
    "        return self.length\n",
    "        #return 1058750 # pre-calculated length of 10M data set\n",
    "        #return 10587561\n",
    "    \n",
    "    def read_file(self, path):\n",
    "        \"\"\"\n",
    "        reads a given file\n",
    "        \"\"\"\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "        return lines\n",
    "\n",
    "    def get_encodings(self, lines_all):\n",
    "        \"\"\"\n",
    "        Creates encodings for a given text input\n",
    "        \"\"\"\n",
    "        # tokenise all text \n",
    "        batch = self.tokenizer(lines_all, max_length=128, padding='max_length', truncation=True)\n",
    "\n",
    "        # Ground Truth\n",
    "        labels = torch.tensor(batch['input_ids'])\n",
    "        # Attention Masks\n",
    "        mask = torch.tensor(batch['attention_mask'])\n",
    "\n",
    "        # Input to be masked\n",
    "        input_ids = labels.detach().clone()\n",
    "        rand = torch.rand(input_ids.shape)\n",
    "\n",
    "        # with a probability of 15%, mask a given word, leave out CLS, SEP and PAD\n",
    "        mask_arr = (rand < .15) * (input_ids != 0) * (input_ids != 2) * (input_ids != 3)\n",
    "        # assign token 4 (=MASK)\n",
    "        input_ids[mask_arr] = 4\n",
    "        \n",
    "        return {'input_ids':input_ids, 'attention_mask':mask, 'labels':labels}\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        returns item i\n",
    "        Note: do not use shuffling for this dataset\n",
    "        \"\"\"\n",
    "        # if we have looked at all items in the file - take next\n",
    "        if self.remaining == 0:\n",
    "            self.offset += len(self.data)\n",
    "            self.current_file += 1\n",
    "            # if we are at the end of the dataset, start over again\n",
    "            if self.current_file == len(self.paths):\n",
    "                self.current_file = 0\n",
    "            # self.get_encodings(self.data)\n",
    "            print(\"reading {}\".format(self.paths[self.current_file]))\n",
    "            self.data = self.read_file(self.paths[self.current_file])\n",
    "            self.remaining = len(self.data)\n",
    "        \n",
    "        # reset offset when i is reset\n",
    "        if i == 0:\n",
    "            self.offset = 0\n",
    "        \n",
    "        self.remaining -= 1\n",
    "\n",
    "        encodings = self.get_encodings(self.data[i - self.offset])\n",
    "\n",
    "        return encodings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb5a80-d14b-4633-b7fe-dee478057306",
   "metadata": {},
   "source": [
    "### Set up electra tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a8d5b3-56f1-4ba5-b55f-81499f0849da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 7592, 1010, 2129, 2024, 2017, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] hello, how are you? [SEP]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import ElectraTokenizerFast, ElectraModel, ElectraConfig, ElectraForMaskedLM\n",
    "\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained('google/electra-small-discriminator')\n",
    "\n",
    "tokens = tokenizer('Hello, how are you?')\n",
    "print(tokens)\n",
    "# {'input_ids': [2, 21694, 16, 2287, 2009, 1991, 35, 3],\n",
    "# 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
    "\n",
    "tokenizer.decode(tokens['input_ids'])\n",
    "# '[CLS] hello, how are you? [SEP]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f6a9df-5d1a-4ec4-b2bc-b3b8ef393b42",
   "metadata": {},
   "source": [
    "### Grab all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f033145-e141-40cd-84f1-3b8818c39dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90001\n",
      "580001\n",
      "66015\n",
      "360001\n",
      "65001\n",
      "18001\n"
     ]
    }
   ],
   "source": [
    "# load dataset files one by one\n",
    "paths = [str(x) for x in Path('train_10M').glob('**/*.train')]\n",
    "ds = Dataset(paths, tokenizer=tokenizer)\n",
    "# tokenize data with batch size 16\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f695a6f1-9df2-4a9d-acfb-9c17364fe1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "i = iter(ds)\n",
    "\n",
    "for j in range(10):\n",
    "    sample = next(i)\n",
    "    \n",
    "    input_ids = sample['input_ids']\n",
    "    attention_masks = sample['attention_mask']\n",
    "    labels = sample['labels']\n",
    "    \n",
    "    # check if the dimensions are right\n",
    "    assert input_ids.shape[0] == (128)\n",
    "    assert attention_masks.shape[0] == (128)\n",
    "    assert labels.shape[0] == (128)\n",
    "    \n",
    "    # if the input ids are not masked, the labels are the same as the input ids\n",
    "    assert np.array_equal(input_ids[input_ids != 4].numpy(),labels[input_ids != 4].numpy())\n",
    "    # input ids are zero if the attention masks are zero\n",
    "    assert np.all(input_ids[attention_masks == 0].numpy()==0)\n",
    "    # check if input contains masked tokens (we can't guarantee this 100% but this will apply) most likely\n",
    "    #assert np.any(input_ids.numpy() == 4)\n",
    "print(\"Passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4466bd-9f0b-4ea4-a6b6-e8759548948a",
   "metadata": {},
   "source": [
    "### Get Electra Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13ee29c5-6528-4695-84cf-3c1d02b51946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForMaskedLM(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 64, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 64)\n",
       "      (token_type_embeddings): Embedding(2, 64)\n",
       "      (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=64, out_features=196, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-17): 18 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=196, out_features=196, bias=True)\n",
       "              (key): Linear(in_features=196, out_features=196, bias=True)\n",
       "              (value): Linear(in_features=196, out_features=196, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=196, out_features=196, bias=True)\n",
       "              (LayerNorm): LayerNorm((196,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=196, out_features=128, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=128, out_features=196, bias=True)\n",
       "            (LayerNorm): LayerNorm((196,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator_predictions): ElectraGeneratorPredictions(\n",
       "    (activation): GELUActivation()\n",
       "    (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=196, out_features=64, bias=True)\n",
       "  )\n",
       "  (generator_lm_head): Linear(in_features=64, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL to the config file\n",
    "config_url = \"https://huggingface.co/bsu-slim/electra-tiny/resolve/main/config.json\"\n",
    "\n",
    "# Download the config file\n",
    "response = requests.get(config_url)\n",
    "\n",
    "# Load the JSON content into ElectraConfig using .from_dict\n",
    "config = ElectraConfig.from_dict(response.json())\n",
    "model = ElectraForMaskedLM(config)\n",
    "optim=torch.optim.Adam(model.parameters())\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29d9d1f8-12d7-4223-bd61-2185f643f6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"electra_owt_full_b256_hs196_ah4_is128_l18_es64_vs30522_pytorch\",\n",
       "  \"architectures\": [\n",
       "    \"ElectraForPreTraining\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"embedding_size\": 64,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 196,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 128,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"electra\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 18,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"summary_activation\": \"gelu\",\n",
       "  \"summary_last_dropout\": 0.1,\n",
       "  \"summary_type\": \"first\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.49.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb3dfc8-7bf7-42ea-8579-cc3e8e1c6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.optim import AdamW\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e86c27d9-8e68-43f2-9275-57338cf811d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use AdamW as the optimiser\n",
    "optim = AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1fba014-9336-472e-a1e7-9e65d17ecd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2dd636b32f48e3a7f0e86612627277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n",
      "reading train_10M\\bnc_spoken.train\n",
      "Mean Training Loss 0.24338584062980162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c456f5da98649a990baa37555be6943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n",
      "reading train_10M\\bnc_spoken.train\n",
      "Mean Training Loss 0.0801780707593125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2753a4335d2497da9c687d65958cd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n",
      "reading train_10M\\bnc_spoken.train\n",
      "Mean Training Loss 0.07501595280145068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8b9ef2df8149a9bcc462ae39003b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n",
      "reading train_10M\\bnc_spoken.train\n",
      "Mean Training Loss 0.07169152818006169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605f3627f5064026a75caf85e57cf5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n",
      "reading train_10M\\bnc_spoken.train\n",
      "Mean Training Loss 0.068760689341164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b9b0d8c1204b4a87af491dda58773c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n",
      "reading train_10M\\bnc_spoken.train\n",
      "Mean Training Loss 0.0663094697193877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a787ad0841264b8d848ccd1c3a45677f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n",
      "reading train_10M\\bnc_spoken.train\n",
      "Mean Training Loss 0.06451682619906615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68854dfcb680419b958d034d20102344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n",
      "reading train_10M\\bnc_spoken.train\n",
      "Mean Training Loss 0.06279580554748\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005a570dc6624b6e9159b817766de7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n",
      "reading train_10M\\bnc_spoken.train\n",
      "Mean Training Loss 0.061605543963385405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0040a333b26c45fbb2539fbd6c2d40ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train_10M\\childes.train\n",
      "reading train_10M\\gutenberg.train\n",
      "reading train_10M\\open_subtitles.train\n",
      "reading train_10M\\simple_wiki.train\n",
      "reading train_10M\\switchboard.train\n",
      "reading train_10M\\bnc_spoken.train\n",
      "Mean Training Loss 0.06059068696942291\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    # iterate over dataset\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # copy input to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # predict\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        # update weights\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        # output current loss\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    print(\"Mean Training Loss\", np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39b4d3b0-f27c-4b41-8ecb-54108573e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pretrained model\n",
    "torch.save(model.state_dict(), \"pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8a785b3-da88-40d7-9557-35ed3908e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save config\n",
    "config.to_json_file(\"config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3749ec38-2f3d-44d4-aa14-c3ad5a22f20a",
   "metadata": {},
   "source": [
    "### Evaluation and Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8dc00-ee85-46a6-8850-02c8c06ab730",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa5e7caf-a9f3-46b1-b235-ca4ba389faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [line.strip() for line in open('X.txt').readlines()]\n",
    "y = train_data = [int(line.strip()) for line in open('YL1.txt').readlines()]\n",
    "\n",
    "train_X = X[:46000]\n",
    "train_y = np.array(y[:46000])\n",
    "test_X = X[46000:]\n",
    "test_y = np.array(y[46000:])\n",
    "\n",
    "labels = {\n",
    "    0:'Computer Science',\n",
    "    1:'Electrical Engineering',\n",
    "    2:'Psychology',\n",
    "    3:'Mechanical Engineering',\n",
    "    4:'Civil Engineering',\n",
    "    5:'Medical Science',\n",
    "    6:'Biochemistry'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88ec3d-768d-4a0e-85a3-350aee1364fd",
   "metadata": {},
   "source": [
    "#### Define Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffea750d-baa0-4749-a0e1-516bd4737b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = text\n",
    "        self.targets = labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class ELECTRAClass(torch.nn.Module):\n",
    "    def __init__(self, NUM_OUT):\n",
    "        super(ELECTRAClass, self).__init__()\n",
    "                   \n",
    "        self.l1 = ElectraModel.from_pretrained(\"./electra_tiny_model\")\n",
    "        # ELECTRA tiny has 196 hidden units\n",
    "        self.classifier = torch.nn.Linear(196, NUM_OUT)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        output = self.classifier(pooler)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd278bad-8fd7-46be-af8f-9a0192b76171",
   "metadata": {},
   "source": [
    "#### Define Loss and Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e76dc83-15ad-4b26-ba20-835b9b2d2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    # Change to cross entropy\n",
    "    return torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "\n",
    "def train(model, training_loader, optimizer):\n",
    "    model.train()\n",
    "    for data in tqdm(training_loader):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss\n",
    "    \n",
    "def validation(model, testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testing_loader):\n",
    "            targets = data['targets']\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            #outputs = torch.sigmoid(outputs).cpu().detach()\n",
    "            fin_outputs.extend(outputs.cpu().detach())\n",
    "            fin_targets.extend(targets)\n",
    "    return torch.stack(fin_outputs), torch.stack(fin_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c9d15-8fe5-4e63-b86a-538b37d24cfb",
   "metadata": {},
   "source": [
    "#### Format DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba7f8f8e-6996-4c69-b176-50f3af837ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "NUM_OUT = 7\n",
    "LEARNING_RATE = 2e-05\n",
    "\n",
    "training_data = MultiLabelDataset(train_X, torch.from_numpy(train_y), tokenizer, MAX_LEN)\n",
    "test_data = MultiLabelDataset(test_X, torch.from_numpy(test_y), tokenizer, MAX_LEN)\n",
    "\n",
    "train_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }    \n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_data, **train_params)\n",
    "testing_loader = torch.utils.data.DataLoader(test_data, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1341e9c5-21d3-4ea9-b7dd-9a24a66641a7",
   "metadata": {},
   "source": [
    "#### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d97dd196-eaee-487e-84a6-e744cec7446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25b87419-f51d-4dd5-9f85-4ffbf899e911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451de346279b41da880e15bf444bb6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reggi\\AppData\\Local\\Temp\\ipykernel_30060\\519072124.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'targets': torch.tensor(self.targets[index], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.5766854286193848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945b62b901de4fffa6bb344453e44565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.749238578680203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5015ce80d3704c22ba213e08370cb154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reggi\\AppData\\Local\\Temp\\ipykernel_30060\\519072124.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'targets': torch.tensor(self.targets[index], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.28415295481681824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e819e0c18194f56a561e36982a4e58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7746192893401015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b70cacd71e43e78ec6675dfde9d679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reggi\\AppData\\Local\\Temp\\ipykernel_30060\\519072124.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'targets': torch.tensor(self.targets[index], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.7769172191619873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bdcc9463d864ec7bf3bc64a41bb5848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7888324873096447\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3ec977bfd742c5a07bdd2ea9bdcafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reggi\\AppData\\Local\\Temp\\ipykernel_30060\\519072124.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'targets': torch.tensor(self.targets[index], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.13983726501464844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4796dbef51a743e7bc8e547b16278bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7918781725888325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806d2a232d674b2c96756896601ec4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reggi\\AppData\\Local\\Temp\\ipykernel_30060\\519072124.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'targets': torch.tensor(self.targets[index], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.4454813301563263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43a37a7bcb54e7290f0283d04712c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.782741116751269\n"
     ]
    }
   ],
   "source": [
    "model = ELECTRAClass(NUM_OUT)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train(model, training_loader, optimizer)\n",
    "    print(f'Epoch: {epoch}, Loss: {loss.mean().item()}')\n",
    "    guess, targs = validation(model, testing_loader)\n",
    "    guesses = torch.max(guess, dim=1).indices\n",
    "    targets = targs\n",
    "    print('Accuracy on test set: {}'.format(accuracy_score(guesses, targets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f0b4b5-260f-43c8-9f1b-66562f86b218",
   "metadata": {},
   "source": [
    "Questions\n",
    "\n",
    "1. How well did your model perform on the evaluation compared to BERT?\n",
    "Compared to BERT, which I was able to get 84% accuracy on the same fine-tuning test, it did worse, only getting a high of 79% on epoch 3.\n",
    "2. What is the difference between pre training and fine-tuning?\n",
    "Pre training requires more computational resources becuase it requires more data as the weights in the model are randomly initialized.  Fine-tuning is different because it requires less data and uses a pre trained model which has trained weights, this makes it more computationally effective.\n",
    "3. Why do you think pre training requires more compute resources than fine-tuning?\n",
    "- The amount of data required to pre train is far greater than for fine-tuning\n",
    "- Weights are randomly initialized during pre training\n",
    "- Diversity of data probably needs to be greater for pre training\n",
    "- Pre training is an unsupervised learning task while fine tuning is supervised https://www.ibm.com/think/topics/supervised-vs-unsupervised-learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
